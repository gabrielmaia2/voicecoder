
Skip to main content
Cornell University
We gratefully acknowledge support from the Simons Foundation, member institutions , and all contributors. Donate
arxiv logo > cs > arXiv:1904.07556

Help | Advanced Search
Search
Computer Science > Computation and Language
(cs)
[Submitted on 16 Apr 2019 ( v1 ), last revised 28 Jun 2019 (this version, v2)]
Title: Unsupervised acoustic unit discovery for speech synthesis using discrete latent-variable neural networks
Authors: Ryan Eloff , André Nortje , Benjamin van Niekerk , Avashna Govender , Leanne Nortje , Arnu Pretorius , Elan van Biljon , Ewald van der Westhuizen , Lisa van Staden , Herman Kamper
Download a PDF of the paper titled Unsupervised acoustic unit discovery for speech synthesis using discrete latent-variable neural networks, by Ryan Eloff and 9 other authors
Download PDF

    Abstract: For our submission to the ZeroSpeech 2019 challenge, we apply discrete latent-variable neural networks to unlabelled speech and use the discovered units for speech synthesis. Unsupervised discrete subword modelling could be useful for studies of phonetic category learning in infants or in low-resource speech technology requiring symbolic input. We use an autoencoder (AE) architecture with intermediate discretisation. We decouple acoustic unit discovery from speaker modelling by conditioning the AE's decoder on the training speaker identity. At test time, unit discovery is performed on speech from an unseen speaker, followed by unit decoding conditioned on a known target speaker to obtain reconstructed filterbanks. This output is fed to a neural vocoder to synthesise speech in the target speaker's voice. For discretisation, categorical variational autoencoders (CatVAEs), vector-quantised VAEs (VQ-VAEs) and straight-through estimation are compared at different compression levels on two languages. Our final model uses convolutional encoding, VQ-VAE discretisation, deconvolutional decoding and an FFTNet vocoder. We show that decoupled speaker conditioning intrinsically improves discrete acoustic representations, yielding competitive synthesis quality compared to the challenge baseline. 

Comments: 	Interspeech 2019
Subjects: 	Computation and Language (cs.CL) ; Machine Learning (cs.LG); Sound (cs.SD); Audio and Speech Processing (eess.AS)
Cite as: 	arXiv:1904.07556 [cs.CL]
  	(or arXiv:1904.07556v2 [cs.CL] for this version)
  	https://doi.org/10.48550/arXiv.1904.07556
Focus to learn more
arXiv-issued DOI via DataCite
Submission history
From: Herman Kamper [ view email ]
[v1] Tue, 16 Apr 2019 09:38:01 UTC (222 KB)
[v2] Fri, 28 Jun 2019 12:04:07 UTC (222 KB)
Full-text links:
Access Paper:

    Download a PDF of the paper titled Unsupervised acoustic unit discovery for speech synthesis using discrete latent-variable neural networks, by Ryan Eloff and 9 other authors
    Download PDF
    PostScript
    Other Formats 

( view license )
Current browse context:
cs.CL
< prev   |   next >
new | recent | 1904
Change to browse by:
cs
cs.LG
cs.SD
eess
eess.AS
References & Citations

    NASA ADS
    Google Scholar
    Semantic Scholar

DBLP - CS Bibliography
listing | bibtex
Ryan Eloff
André Nortje
Benjamin van Niekerk
Avashna Govender
Leanne Nortje
…
a export BibTeX citation Loading...
Bookmark
BibSonomy logo Reddit logo
Bibliographic Tools
Bibliographic and Citation Tools
Bibliographic Explorer Toggle
Bibliographic Explorer ( What is the Explorer? )
Litmaps Toggle
Litmaps ( What is Litmaps? )
scite.ai Toggle
scite Smart Citations ( What are Smart Citations? )
Code, Data, Media
Demos
Related Papers
About arXivLabs
Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )

    About
    Help

    contact arXiv Click here to contact arXiv Contact
    subscribe to arXiv mailings Click here to subscribe Subscribe

    Copyright
    Privacy Policy

    Web Accessibility Assistance

    arXiv Operational Status
    Get status notifications via email or slack

