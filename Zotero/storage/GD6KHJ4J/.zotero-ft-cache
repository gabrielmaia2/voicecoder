
Skip to main content
Cornell University
We gratefully acknowledge support from the Simons Foundation, member institutions , and all contributors. Donate
arxiv logo > cs > arXiv:2112.02796

Help | Advanced Search
Search
Computer Science > Sound
(cs)
[Submitted on 6 Dec 2021]
Title: Conditional Deep Hierarchical Variational Autoencoder for Voice Conversion
Authors: Kei Akuzawa , Kotaro Onishi , Keisuke Takiguchi , Kohki Mametani , Koichiro Mori
Download a PDF of the paper titled Conditional Deep Hierarchical Variational Autoencoder for Voice Conversion, by Kei Akuzawa and 4 other authors
Download PDF

    Abstract: Variational autoencoder-based voice conversion (VAE-VC) has the advantage of requiring only pairs of speeches and speaker labels for training. Unlike the majority of the research in VAE-VC which focuses on utilizing auxiliary losses or discretizing latent variables, this paper investigates how an increasing model expressiveness has benefits and impacts on the VAE-VC. Specifically, we first analyze VAE-VC from a rate-distortion perspective, and point out that model expressiveness is significant for VAE-VC because rate and distortion reflect similarity and naturalness of converted speeches. Based on the analysis, we propose a novel VC method using a deep hierarchical VAE, which has high model expressiveness as well as having fast conversion speed thanks to its non-autoregressive decoder. Also, our analysis reveals another problem that similarity can be degraded when the latent variable of VAEs has redundant information. We address the problem by controlling the information contained in the latent variable using Î² -VAE objective. In the experiment using VCTK corpus, the proposed method achieved mean opinion scores higher than 3.5 on both naturalness and similarity in inter-gender settings, which are higher than the scores of existing autoencoder-based VC methods. 

Subjects: 	Sound (cs.SD) ; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)
Cite as: 	arXiv:2112.02796 [cs.SD]
  	(or arXiv:2112.02796v1 [cs.SD] for this version)
  	https://doi.org/10.48550/arXiv.2112.02796
Focus to learn more
arXiv-issued DOI via DataCite
Submission history
From: Kei Akuzawa [ view email ]
[v1] Mon, 6 Dec 2021 05:54:11 UTC (294 KB)
Full-text links:
Access Paper:

    Download a PDF of the paper titled Conditional Deep Hierarchical Variational Autoencoder for Voice Conversion, by Kei Akuzawa and 4 other authors
    Download PDF
    PostScript
    Other Formats 

( view license )
Current browse context:
cs.SD
< prev   |   next >
new | recent | 2112
Change to browse by:
cs
cs.LG
eess
eess.AS
References & Citations

    NASA ADS
    Google Scholar
    Semantic Scholar

DBLP - CS Bibliography
listing | bibtex
Kei Akuzawa
Kohki Mametani
a export BibTeX citation Loading...
Bookmark
BibSonomy logo Reddit logo
Bibliographic Tools
Bibliographic and Citation Tools
Bibliographic Explorer Toggle
Bibliographic Explorer ( What is the Explorer? )
Litmaps Toggle
Litmaps ( What is Litmaps? )
scite.ai Toggle
scite Smart Citations ( What are Smart Citations? )
Code, Data, Media
Demos
Related Papers
About arXivLabs
Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )

    About
    Help

    contact arXiv Click here to contact arXiv Contact
    subscribe to arXiv mailings Click here to subscribe Subscribe

    Copyright
    Privacy Policy

    Web Accessibility Assistance

    arXiv Operational Status
    Get status notifications via email or slack

