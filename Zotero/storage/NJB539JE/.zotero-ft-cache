IEEE websites place cookies on your device to give you the best user experience. By using our websites, you agree to the placement of these cookies. To learn more, read our Privacy Policy.
Accept & Close
Skip to Main Content

    IEEE.org
    IEEE Xplore
    IEEE SA
    IEEE Spectrum
    More Sites 

Subscribe

        Cart 
        Create Account
        Personal Sign In 

IEEE Xplore logo - Link to home

    Browse
    My Settings
    Help

Institutional Sign In
IEEE logo - Link to IEEE main site homepage
ADVANCED SEARCH
Journals & Magazines > Proceedings of the IEEE > Volume: 105 Issue: 12
Efficient Processing of Deep Neural Networks: A Tutorial and Survey
Publisher: IEEE
Cite This
PDF
Vivienne Sze ; Yu-Hsin Chen ; Tien-Ju Yang ; Joel S. Emer
All Authors
2011
Cites in
Papers
76
Cites in
Patents
49501
Full
Text Views

    Alerts

Abstract
Document Sections

    I.
    Introduction
    II.
    Background on DNNs
    III.
    Overview of DNNs
    IV.
    DNN Development Resources
    V.
    Hardware for DNN Processing

Show Full Outline
Authors
Figures
References
Citations
Keywords
Metrics
Footnotes
Abstract:
Deep neural networks (DNNs) are currently widely used for many artificial intelligence (AI) applications including computer vision, speech recognition, and robotics. While DNNs deliver state-of-the-art accuracy on many AI tasks, it comes at the cost of high computational complexity. Accordingly, techniques that enable efficient processing of DNNs to improve energy efficiency and throughput without sacrificing application accuracy or increasing hardware cost are critical to the wide deployment of DNNs in AI systems. This article aims to provide a comprehensive tutorial and survey about the recent advances toward the goal of enabling efficient processing of DNNs. Specifically, it will provide an overview of DNNs, discuss various hardware platforms and architectures that support DNNs, and highlight key trends in reducing the computation cost of DNNs either solely via hardware design changes or via joint hardware design and DNN algorithm changes. It will also summarize various development resources that enable researchers and practitioners to quickly get started in this field, and highlight important benchmarking metrics and design considerations that should be used for evaluating the rapidly growing number of DNN hardware designs, optionally including algorithmic codesigns, being proposed in academia and industry. The reader will take away the following concepts from this article: understand the key design considerations for DNNs; be able to evaluate different DNN hardware implementations with benchmarks and comparison metrics; understand the tradeoffs between various hardware architectures and platforms; be able to evaluate the utility of various DNN design techniques for efficient processing; and understand recent implementation trends and opportunities.
Published in: Proceedings of the IEEE ( Volume: 105 , Issue: 12 , December 2017 )
Page(s): 2295 - 2329
Date of Publication: 20 November 2017
ISSN Information:
INSPEC Accession Number: 17372031
DOI: 10.1109/JPROC.2017.2761740
Publisher: IEEE
Funding Agency:
I. Introduction

Deep neural networks (DNNs) are currently the foundation for many modern artificial intelligence (AI) applications [1]. Since the breakthrough application of DNNs to speech recognition [2] and image recognition [3], the number of applications that use DNNs has exploded. These DNNs are employed in a myriad of applications from self-driving cars [4], to detecting cancer [5] to playing complex games [6]. In many of these domains, DNNs are now able to exceed human accuracy. The superior performance of DNNs comes from its ability to extract high-level features from raw sensory data after using statistical learning over a large amount of data to obtain an effective representation of an input space. This is different from earlier approaches that use hand-crafted features or rules designed by experts.
Sign in to Continue Reading
Authors
Figures
References
Citations
Keywords
Metrics
Footnotes
More Like This
Improving the Performance of an Artificial Intelligence Recommendation Engine with Deep Learning Neural Nets

2021 6th International Conference for Convergence in Technology (I2CT)

Published: 2021
Quantum machine learning-using quantum computation in artificial intelligence and deep neural networks: Quantum computation and machine learning in artificial intelligence

2017 8th Annual Industrial Automation and Electromechanical Engineering Conference (IEMECON)

Published: 2017
Show More
References
References is not available for this document.
IEEE Personal Account

    Change username/password 

Purchase Details

    Payment Options
    View Purchased Documents 

Profile Information

    Communications Preferences
    Profession and Education
    Technical interests 

Need Help?

    US & Canada: +1 800 678 4333
    Worldwide: +1 732 981 0060
    Contact & Support 

Follow

About IEEE Xplore | Contact Us | Help | Accessibility | Terms of Use | Nondiscrimination Policy | IEEE Ethics Reporting | Sitemap | IEEE Privacy Policy

A not-for-profit organization, IEEE is the world's largest technical professional organization dedicated to advancing technology for the benefit of humanity.

Â© Copyright 2023 IEEE - All rights reserved.
